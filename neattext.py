# -*- coding: utf-8 -*-
"""neattext.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bixlRpz9VFMuALAsjs8ixhZ61cYwuhvB
"""

!pip install neattext

from google.colab import files
uploaded = files.upload()

import pandas as pd
import os
import neattext as nt
import neattext.functions as nfx

dir(nt)



data = pd.read_csv('twitter4000.csv')

data

dir(nt)

s = data.iloc[4]['twitts']

s

# using textframe
docx = nt.TextFrame(s)

docx.describe()

# preview the first 10 characters
docx.head(10)

# remove stop wrods
docx.remove_stopwords().text

# remove puncts
docx.remove_puncts().text

# remove puncts
docx.remove_puncts(most_common = False).text

# remove puncts
docx.remove_puncts(most_common = True).text

nfx.remove_userhandles(s)

nfx.remove_hashtags(s)

nfx.remove_special_characters(s)

nfx.remove_stopwords(s)

#clean text
s2 = '@mandagoforth me bad! Its funny though. Zachary Quinto is only there for a few though.  &amp; to reply just put the @ symbol before the name!'

s2

nfx.clean_text(s2)

nfx.clean_text(s2, puncts=False, stopwords=True, emails=True, urls=True)

#working on datatset
data

# moise scan
data['twitts'].apply(lambda x: nt.TextFrame(x).noise_scan()['text_noise'])

#remove userhandles
data['userhandles'] = data['twitts'].apply(nfx.extract_userhandles)

data

data['clean_tweet'] = data['twitts'].apply(nfx.remove_userhandles)

data

# extract hashtags
data['hashtags'] = data['clean_tweet'].apply(nfx.extract_hashtags)

# remove hashtags
data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_hashtags)

data

data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_special_characters)

data

data['clean_tweet'] = data['clean_tweet'].apply(nfx.remove_multiple_spaces)

data.head()

data['clean_tweet'] = data['clean_tweet'].apply(lambda x: nt.TextExtractor(x).remove_stopwords())

x = 'i am ðŸ˜ž '

data['clean_tweet'] = data['clean_tweet'].apply(nfx.replace_emojis()

dir(nfx)

